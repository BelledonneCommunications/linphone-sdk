# Copyright (c) 2010-2025 Belledonne Communications SARL.
#
# This file is part of mediastreamer2
# (see https://gitlab.linphone.org/BC/public/mediastreamer2).
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

"""Analyze the quality of the adenoising.

The analysis is based on the metrics read in log file and other that are computed on audio data.
"""

import re

import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from tools.common.audio.audio_comparison import AudioComparison
from tools.common.audio.audio_signal import AudioSignal


class AudioAnalysisNoiseSuppression:
    """Handle the analysis of audio data generated by a test of the Noise Suppression suite."""

    def __init__(self, speech: AudioSignal, noisy_speech: AudioSignal, clean: AudioSignal, test_name: str) -> None:
        """Set the audio signals and analysis parameters.

        :param speech: Initial speech signal, without noise, taken as reference.
        :type speech: AudioSignal
        :param noisy_speech: Speech signal with noise added.
        :type noisy_speech: AudioSignal
        :param clean: Denoised signal, output of a test from the Noise Suppression suite.
        :type clean: AudioSignal
        :param test_name: Name of the test used applied on noisy_speech to get clean audio.
        :type test_name: str
        """
        self.speech = speech
        self.noisy_speech = noisy_speech
        self.clean = clean
        self.test_name = test_name
        self.log_file = ""
        self.comparison = AudioComparison()
        self.sampling_rate_hz = 0
        self.energy_in_silence = 0.0
        self.energy_in_silence_with_noise = 0.0
        self.similarity_in_speech = 0.0
        self.msticker_late_ms = []
        self.maxpos = 0
        self.test_passed = 0
        self.asserts = 0
        self.total_time_s = 0.0
        self.silence_mask = None
        self.start_time_ms = 0
        self.start_sample = 0
        self.distance_mfcc = 0.0
        self.similarity_mfcc = 0.0
        self.filter_stats = np.zeros(6)

    def get_results(self, log_file: str) -> None:
        """Extract the results of the test from log.

        A Noise Suppressor filtering has been applied during the test. Some information is extracted from the log file.
        :param log_file: Full file name of the log file.
        :type log_file: str
        """
        self.log_file = log_file
        float_pattern = r"\d+\.\d+|\d+"
        with open(log_file) as f:
            contents = f.readlines()
            for i, line in enumerate(contents):
                if "Noise added with gain" in line:
                    match = re.search(r"([0-9]+\.[0-9]+)", line.split("Noise added with gain = ")[-1])
                    if match:
                        self.noise_gain = float(match.group(1))

                if "MSNoiseSuppressor" in line and "initialized for " in line:
                    self.sampling_rate_hz = int(line.split("initialized for ")[-1].split(" Hz")[0])
                    print(f"sampling rate found is {self.sampling_rate_hz} Hz")

                if "chunk - max cross-correlation obtained at position " in line and self.maxpos == 0:
                    match = re.search(
                        r"\[(-?\d+)\]",
                        line.split("obtained at position ")[-1].split(", similarity factor")[0],
                    )
                    if match:
                        self.maxpos = int(match.group(1))

                if " similarity in talk" in line:
                    match = re.search(
                        r"([0-9]+\.[0-9]+)",
                        line.split("similarity in talk = ")[-1].split(" - min")[0],
                    )
                    if match:
                        self.similarity_in_speech = float(match.group(1).replace(",", "."))

                if "energy in silence = " in line:
                    match = re.search(
                        r"([0-9]+\.[0-9]+)",
                        line.split("energy in silence = ")[-1].split(" - max =")[0],
                    )
                    if match:
                        self.energy_in_silence = float(match.group(1).replace(",", "."))

                if "energy in silence of noisy audio = " in line:
                    match = re.search(
                        r"([0-9]+\.[0-9]+)",
                        line.split("energy in silence of noisy audio = ")[-1].split(", the remainig energy")[0],
                    )
                    if match:
                        self.energy_in_silence_with_noise = float(match.group(1).replace(",", "."))

                if "Tester MSTicker: We are late of" in line:
                    late_str = line.split("Tester MSTicker: We are late of ")[-1].split(" miliseconds.")[0]
                    self.msticker_late_ms.append(int(late_str))

                if "FILTER USAGE STATISTICS" in line:
                    filter_name = "MSNoiseSuppressor"
                    k = i + 4
                    if k < len(contents):
                        stats_line = contents[k]
                        while (
                            k < len(contents)
                            and filter_name not in stats_line
                            and "=======================" not in stats_line
                        ):
                            stats_line = contents[k]
                            k = k + 1
                        if filter_name in stats_line:
                            stats_line = stats_line.replace(",", ".")
                            self.filter_stats = np.array(
                                [float(num) for num in re.findall(float_pattern, stats_line.split(filter_name)[1])]
                            )

                if "Suite [Noise suppression] Test [" in line:
                    if "passed in" in line:
                        self.test_passed = 1
                    elif "failed in" in line:
                        self.test_passed = 0
                    total_time_str = line.split("in ")[-1].split(" secs")[0]
                    match = re.search(r"([0-9]+\.[0-9]+)", total_time_str)
                    if match:
                        self.total_time_s = float(match.group(1))

                if "Run Summary:    Type  Total    Ran Passed Failed Inactive" in line:
                    k = i + 3
                    if k < len(contents) and "asserts" in contents[k]:
                        integers = [int(num) for num in contents[k].split() if num.isdigit()]
                        self.asserts = integers[3]

    def print(self) -> None:
        """Print the results of the AEC test."""
        if len(self.msticker_late_ms) > 0:
            print(f"MSticker late: \t{self.msticker_late_ms} ms")
        if self.clean is not None:
            print(
                f"maxpos: \t\t\t\t{self.maxpos} samples\n\t\t\t\t\t\
{self.maxpos * 1000.0 / self.clean.sample_rate_hz:0.0f} ms"
            )
        else:
            print(
                f"maxpos: \t\t\t\t{self.maxpos} samples\n\t\t\t\t\t\
{self.maxpos * 1000.0 / self.sampling_rate_hz:0.0f} ms"
            )

        print(f"energy in silence of clean audio: \t{self.energy_in_silence:0.1f}")
        print(f"energy in silence of noisy audio: \t{self.energy_in_silence_with_noise:0.1f}")
        print(f"similarity in speech: \t\t\t{self.similarity_in_speech:0.3f}")
        print(f"           with MFCC: \t\t\t{self.similarity_mfcc:0.3f}")

        if self.filter_stats is not None:
            print(f"filter usage stats: \tcount\t\t{self.filter_stats[0]:0.0f}")
            print(f"\t\t\ttime\tmin\t{self.filter_stats[1]:0.2f} ms")
            print(f"\t\t\t\tmean\t{self.filter_stats[2]:0.2f} ms")
            print(f"\t\t\t\tmax\t{self.filter_stats[3]:0.2f} ms")
            print(f"\t\t\t\tstd\t{self.filter_stats[4]:0.2f} ms")
            print(f"\t\t\tCPU usage\t{self.filter_stats[5]:0.2f} %")

        print(f"test passed: \t\t\t\t{self.test_passed}")
        print(f"total time: \t\t\t\t{self.total_time_s:0.1f} s")

    def align_on_speech(self, start_time_ms: int = 0, alignment_interval_ms: [int, int] = None) -> None:
        """Align the noisy audio and the filtered output audio with reference audio on the maximal correlation.

        :param start_analysis_ms: Time stamp to start the audio analysis, in ms. Default is 0.
        :type start_analysis_ms: int
        :param alignment_interval_ms: Begin and end of the small time interval taken to align the aec output audio on
            the near-end. If not given, the correlation is computed on the whole signal, but it takes more time. Default
            is None.
        :type alignment_interval_ms: [int, int]
        """
        print("  Align clean audio on initial speech --")
        self.comparison.align_signal_on_reference(self.clean, self.speech, start_time_ms, alignment_interval_ms)
        print("  Align noisy speech on initial speech --")
        self.comparison.align_signal_on_reference(self.noisy_speech, self.speech, start_time_ms, alignment_interval_ms)

        audio_list = [self.speech, self.noisy_speech, self.clean]
        self.comparison.truncate_aligned_end_to_same_size(audio_list)

    def plot_audio(self, audio: AudioSignal, fig_title: str = "") -> go.Figure:
        """Plot the audio and return the plotly figure.

        :param audio: Audio signal to plot.
        :type audio: AudioSignal
        :param fig_title: Optional, title of the figure. Default is empty.
        :type fig_title: str
        :return: Plotly figure
        :rtype: go.Figure
        """
        sample_duration_s = 1.0 / audio.sample_rate_hz
        signal_name = ["full audio", "aligned"]
        n_rows = len(signal_name)
        fig = make_subplots(rows=n_rows, cols=1, shared_xaxes=True)
        for i, audio_signal in enumerate([audio.data, audio.aligned_data]):
            if audio_signal is not None:
                timestamp = sample_duration_s * np.arange(audio_signal.size)
                signal = audio_signal / np.max(np.abs(audio_signal))
                fig.add_trace(
                    go.Scatter(
                        x=timestamp,
                        y=signal,
                        mode="lines",
                        line={"width": 1},
                        name=f"{signal_name[i]}",
                    ),
                    row=i + 1,
                    col=1,
                )
            fig.update_yaxes(title_text=f"{signal_name[i]}", range=[-1.0, 1.0], row=i + 1, col=1)
        fig.update_layout(title=fig_title)
        fig.update_xaxes(title_text="Time")
        fig.show()

        return fig

    def compute_denoising_quality(
        self,
        log_file: str,
        start_analysis_ms: int = 0,
        alignment_interval_ms: [int, int] = None,
        plot_silence_and_talk: bool = True,
    ) -> None:
        """Compute or load criteria to measure the quality of the denoising.

        :param log_file: Full file name of the log file that contains the traces of the Noise Suppression test.
        :type log_file: str
        :param start_analysis_ms: Time stamp to start the audio analysis, in ms. Default is 0.
        :type start_analysis_ms: int
        :param alignment_interval_ms: Begin and end of the small time interval taken to align the clean audio on the
            speech audio. If not given, the correlation is computed on the whole signal, but it takes more time. Default
            is None.
        :type alignment_interval_ms: [int, int]
        :param plot_silence_and_talk: True whether the audio must be plotted with silence and talk parts. Default is
            True.
        :type plot_silence_and_talk: bool
        """
        # load results in log file
        self.get_results(log_file)

        if self.clean.data is not None:
            self.comparison.set_audio(self.clean, self.speech)

            # align
            print("--- align on reference and detect silence ---")
            self.start_sample = self.comparison.set_start_analysis(start_analysis_ms)
            self.comparison.truncate_reference()
            self.align_on_speech(start_analysis_ms, alignment_interval_ms)

            # detect silence and talk
            self.comparison.detect_silence(self.noisy_speech)
            if plot_silence_and_talk:
                fig_title = f"Silence and talk to compare, {self.test_name}"
                legend = ["Reference", "Denoised output", "Noisy input"]
                self.comparison.plot_silence_and_talk(fig_title, legend, self.noisy_speech)

            # compute energy remaining in silence of noisy audio and clean audio
            print("--- energy in silence ---")
            [energy_in_silence, self.energy_in_silence_with_noise] = self.comparison.compute_energy_difference(
                self.noisy_speech
            )
            if self.energy_in_silence == 0.0:
                self.energy_in_silence = energy_in_silence

            # compute speech similarity
            if self.speech.talk is not None:
                print("--- similarity in talk ---")
                file_name_base = self.log_file.split(".log")[0]
                self.similarity_mfcc, self.distance_mfcc = self.comparison.compute_acoustic_similarity(file_name_base)
